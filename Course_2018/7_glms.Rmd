### Занятие 7 Обобщенные линейные модели, продолжение

График для пуассоновской регрессии
```{r}
plot(jitter(nclutch)~jd, data=Data, pch='.', cex=2)
XX<-seq(min(Data$jd), max(Data$jd))
XX<-seq(min(Data$jd), 250)

Y<-predict(GLM1, newdata=data.frame(jd=XX), se.fit=TRUE)
str(Y)
Y_df<-data.frame(jd=XX, 
                 Y=exp(Y$fit),
   Y_LCI=exp(Y$fit-1.96*Y$se.fit),
   Y_UCI=exp(Y$fit+1.96*Y$se.fit))
 
plot(jitter(nclutch)~jd, data=Data, pch='.', cex=2, xlim=c(120, 250), ylim=c(0, 8.5))

lines(Y~jd, data=Y_df, lwd=2) 
lines(Y_LCI~jd, data=Y_df, lwd=2, lty=2) 
lines(Y_UCI~jd, data=Y_df, lwd=2, lty=2) 
```

Биномиальная регрессия для анализа пропорций 
```{r}   
download.file("https://git.io/vxZRh", "Geese_proportion.csv")

Data<-read.csv2("Geese_proportion.csv", as.is=TRUE)
   
head(Data)   

plot(Data$Autumn/(Data$Autumn+Data$Spring) ~Data$Year)

GLM4<-glm(cbind(Data$Autumn,Data$Spring)~Data$Year, family='binomial')

GLM5<-glm(cbind(Data$Autumn,Data$Spring)~1, family='binomial')

summary(GLM5)

AIC(GLM4, GLM5)
```
